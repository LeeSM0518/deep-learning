{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서와 그래프 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로 import\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# 상수를 hello 변수에 저장\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "print(hello)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hello가 텐서플로의 **텐서** 라는 자료형을 담고 있다\n",
    "**텐서는** 텐서플로에서 다양한 수학식을 계산하기 위한 가장 기본적이고 중요한 자료형이다.\n",
    "다음과 같이 **랭크(Rank)** 와 **셰이프(Shape)** 라는 개념을 가지고 있다.\n",
    "\n",
    "</bn>\n",
    "\n",
    "```python\n",
    "3                              # 랭크가 0인 텐서, 셰이프는 []\n",
    "[1., 2., 3.]                   # 랭크가 1인 텐서, 셰이프는 [3]\n",
    "[[1., 2., 3.], [4., 5., 6.]]   # 랭크가 2인 텐서, 셰이프는 [2, 3]\n",
    "```\n",
    "> 텐서 자료형의 형태는 배열과 비슷하다고 생각하면 된다.\n",
    "\n",
    "</bn>\n",
    "\n",
    "**dtype** 은 해당 텐서에 담긴 요소들의 자료형이다. ex) string, float, int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 텐서를 이용한 덧셈\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "c = tf.add(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "42가 나올 것으로 생각할 수 있지만, 위와 같이 텐서의 형태로 출력된다.\n",
    "왜냐하면 텐서플로 프로그램의 구조는 **그래프의 생성과 그래프 실행** 으로 구성되어 있다.\n",
    "\n",
    "<br>\n",
    "\n",
    "* **그래프** : 텐서들의 연산 모음. 연산이 필요할 때만 실행하는 코드를 넣어 <u>원하는 시점</u> 에 실제 연산을 수행하도록 한다.\n",
    "* **그래프 실행** : Session 객체와 run 메소드를 이용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n",
      "[10, 32, 42]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseSession.close of <tensorflow.python.client.session.Session object at 0x1315743c8>>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "print(sess.run(hello))\n",
    "print(sess.run([a, b, c]))\n",
    "\n",
    "sess.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 플레이스홀더와 변수\n",
    "**플레이스홀더** : 그래프에 사용할 입력값을 나중에 받기 위해 사용하는 매개변수\n",
    "**변수** : 그래프를 최적화하는 용도로 텐서플로가 학습한 결과를 갱신하기 위해 사용하는 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 플레이스홀더 사용\n",
    "X = tf.placeholder(tf.float32, [None, 3])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X에 넣을 자료 정의\n",
    "x_data = [[1, 2, 3], [4, 5, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 정의\n",
    "# tf.random_normal : 정규분포의 무작위 값으로 최고화\n",
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행렬 곱셈 실행\n",
    "expr = tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로로 딥러닝을 하기 위해서는 **행렬곱** 정의를 알아야 한다.\n",
    "* 행렬곱 A x B 에 대하여, 행렬 A의 열 수와 행렬 B의 행 수는 같아야 한다.\n",
    "* 행렬곱 A x B 를 계산한 행렬 AB의 크기는 A의 행 개수와 B의 열 개수가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== x_data ===\n",
      "[[1, 2, 3], [4, 5, 6]]\n",
      "=== W ===\n",
      "[[-0.63166183  0.9420165 ]\n",
      " [ 1.354897   -0.08405089]\n",
      " [-0.9487149  -1.0861019 ]]\n",
      "=== b ===\n",
      "[[-0.37491494]\n",
      " [-1.342244  ]]\n",
      "=== expr ===\n",
      "[[-1.1429274 -2.8593056]\n",
      " [-2.7866955 -4.5110435]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseSession.close of <tensorflow.python.client.session.Session object at 0x1315f2a20>>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) # 정의한 변수들을 초기화\n",
    "\n",
    "print(\"=== x_data ===\")\n",
    "print(x_data)\n",
    "print(\"=== W ===\")\n",
    "print(sess.run(W))\n",
    "print(\"=== b ===\")\n",
    "print(sess.run(b))\n",
    "print(\"=== expr ===\")\n",
    "print(sess.run(expr, feed_dict={X: x_data})) # feed_dict : 그래프를 실행할 때 사용할 입력값을 지정\n",
    "\n",
    "sess.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선형 회귀 모델 구현하기\n",
    "**선형 회귀** : 주어진 x 와 y 값을 가지고 서로 간의 관계를 파악하는 것입니다. x 값이 주어졌을 때 y 값을 쉽게 알 수 있다.\n",
    "\n",
    "<br>\n",
    "    \n",
    "x_data 와 y_data의 상관관계를 파악해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1.0 ~ 1.0 사이의 균등분포를 가진 무작위 값으로 초기화\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"X:0\", dtype=float32)\n",
      "Tensor(\"Y:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 자료를 입력받을 플레이스홀더를 설정\n",
    "X = tf.placeholder(tf.float32, name=\"X\") # name 매개변수로 플레이스홀더의 이름을 설정한다.\n",
    "Y = tf.placeholder(tf.float32, name=\"Y\")\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X와 Y의 상관관계(선형관계)를 분석하기 위한 수식 작성\n",
    "hypothesis = W * X + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 수식은 W와의 곱과 b와의 합을 통해 **X와 Y의 관계를** 설명하겠다는 뜻이다.\n",
    "즉, X가 주어졌을 때 Y를 만들어 낼 수 있는 W와 b를 찾아내겠다는 의미이다.\n",
    "* **W** : 가중치\n",
    "* **b** : 편향\n",
    "> 이 수식은 선형 회귀는 물론 신경망 학습에 가장 기본이 되는 수식이다.\n",
    "\n",
    "<br>\n",
    "\n",
    "손실 함수를 작성해보자.\n",
    "* **손실 함수(loss function)** : 한 쌍(x,y)의 데이터에 대한 **손실값**을 계산하는 함수이다.\n",
    "* 손실값 : 실제값과 모델로 예측한 값이 얼마나 차이가 나는지를 나타내는 값\n",
    "> 손실값이 작을수록 X와 Y의 관계가 잘 설명되고 있는 것이며, X 값에 대한 Y 값을 정확하게 예측할 수 있다는 뜻이다.\n",
    "* **비용(cost)** : 손실을 전체 데이터에 대해 구한 경우\n",
    "> 즉 **학습**이란 변수들의 값을 다양하게 넣어 계산해보면서 이 손실값을 최소화하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실값 = (예측값 - 실제값)^2\n",
    "# 모든 데이터에 대한 손실값의 평균을 낸다.\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로 함수을 볼 수 있는 사이트\n",
    "[https://www.tensorflow.org/api_docs/](https://www.tensorflow.org/api_docs/)\n",
    "\n",
    "<br>\n",
    "\n",
    "## 경사하강법 (gradient descent)\n",
    "최적화 함수를 이용해 손실값을 최소화하는 연산 그래프 생성\n",
    "* **최적화 함수** : 가중치와 편향 값을 변경해가면서 손실값을 최소화하는 가장 최적화된 가중치와 편향 값을 찾아주는 함수.\n",
    "* **경사하강법** : 빠르게 최적화하기 위한, 즉 빠르게 학습하기 위한 다양한 방법 중에 가장 기본적인 알고리즘이다.\n",
    "* **learning_rate(학습률)** : 학습을 얼마나 '급하게' 할 것인가를 설정하는 값\n",
    "  * 값이 너무 작으면 학습 속도가 매우 느려지고, 너무 크면 최적의 손실값을 찾지 못한다.\n",
    "* **하이퍼파라미터(hyperparameter)** : 학습을 진행하는 과정에 영향을 주는 변수. 이 값에 따라 학습 속도나 신경망 성능이 크게 달라진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 함수를 이용해 손실값을 최소화하는 연산 그래프 생성 \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 26.296478 [1.2209363] [0.08877015]\n",
      "1 0.31412363 [0.979221] [-0.0173584]\n",
      "2 0.0037589802 [1.005558] [-0.00557513]\n",
      "3 5.1295337e-05 [1.0026006] [-0.0066833]\n",
      "4 6.7053843e-06 [1.0028467] [-0.00638685]\n",
      "5 5.8834253e-06 [1.0027446] [-0.00624817]\n",
      "6 5.597636e-06 [1.0026823] [-0.00609635]\n",
      "7 5.3321396e-06 [1.0026174] [-0.00595001]\n",
      "8 5.078769e-06 [1.0025545] [-0.00580696]\n",
      "9 4.8377087e-06 [1.002493] [-0.00566739]\n",
      "10 4.6077694e-06 [1.0024332] [-0.00553112]\n",
      "11 4.3887358e-06 [1.0023746] [-0.00539817]\n",
      "12 4.1801827e-06 [1.0023175] [-0.00526839]\n",
      "13 3.981929e-06 [1.0022619] [-0.00514175]\n",
      "14 3.7926256e-06 [1.0022075] [-0.00501815]\n",
      "15 3.6124454e-06 [1.0021545] [-0.00489752]\n",
      "16 3.4409766e-06 [1.0021026] [-0.00477981]\n",
      "17 3.2774744e-06 [1.0020521] [-0.00466489]\n",
      "18 3.1217762e-06 [1.0020027] [-0.00455274]\n",
      "19 2.9733249e-06 [1.0019547] [-0.00444328]\n",
      "20 2.8324848e-06 [1.0019076] [-0.0043365]\n",
      "21 2.6975715e-06 [1.0018618] [-0.00423224]\n",
      "22 2.5696472e-06 [1.001817] [-0.00413051]\n",
      "23 2.4474696e-06 [1.0017734] [-0.0040312]\n",
      "24 2.3312386e-06 [1.0017307] [-0.00393431]\n",
      "25 2.2204615e-06 [1.0016891] [-0.00383971]\n",
      "26 2.1151384e-06 [1.0016484] [-0.00374741]\n",
      "27 2.014506e-06 [1.0016088] [-0.00365729]\n",
      "28 1.9188012e-06 [1.0015702] [-0.00356936]\n",
      "29 1.8277052e-06 [1.0015324] [-0.00348358]\n",
      "30 1.7408398e-06 [1.0014956] [-0.00339984]\n",
      "31 1.6582068e-06 [1.0014596] [-0.00331811]\n",
      "32 1.5794598e-06 [1.0014246] [-0.00323833]\n",
      "33 1.5043057e-06 [1.0013903] [-0.00316048]\n",
      "34 1.4328613e-06 [1.001357] [-0.00308451]\n",
      "35 1.3648508e-06 [1.0013243] [-0.00301039]\n",
      "36 1.3002258e-06 [1.0012923] [-0.00293804]\n",
      "37 1.2383633e-06 [1.0012614] [-0.00286738]\n",
      "38 1.1795115e-06 [1.0012311] [-0.00279845]\n",
      "39 1.1233111e-06 [1.0012015] [-0.00273118]\n",
      "40 1.0701224e-06 [1.0011725] [-0.00266554]\n",
      "41 1.019249e-06 [1.0011444] [-0.00260146]\n",
      "42 9.708956e-07 [1.0011169] [-0.00253893]\n",
      "43 9.2479854e-07 [1.00109] [-0.0024779]\n",
      "44 8.808147e-07 [1.0010638] [-0.00241835]\n",
      "45 8.390246e-07 [1.0010383] [-0.00236021]\n",
      "46 7.992174e-07 [1.0010133] [-0.0023035]\n",
      "47 7.6111746e-07 [1.000989] [-0.0022481]\n",
      "48 7.250476e-07 [1.0009651] [-0.00219407]\n",
      "49 6.9050907e-07 [1.000942] [-0.0021413]\n",
      "50 6.5781325e-07 [1.0009193] [-0.00208984]\n",
      "51 6.266013e-07 [1.0008972] [-0.00203962]\n",
      "52 5.96751e-07 [1.0008757] [-0.00199055]\n",
      "53 5.68432e-07 [1.0008546] [-0.00194273]\n",
      "54 5.4154253e-07 [1.000834] [-0.00189604]\n",
      "55 5.156483e-07 [1.0008141] [-0.00185042]\n",
      "56 4.912815e-07 [1.0007944] [-0.00180598]\n",
      "57 4.678609e-07 [1.0007753] [-0.00176254]\n",
      "58 4.4563367e-07 [1.0007567] [-0.00172017]\n",
      "59 4.2449946e-07 [1.0007385] [-0.00167882]\n",
      "60 4.0432155e-07 [1.0007207] [-0.00163846]\n",
      "61 3.8512954e-07 [1.0007035] [-0.00159907]\n",
      "62 3.6686652e-07 [1.0006865] [-0.00156064]\n",
      "63 3.493449e-07 [1.0006701] [-0.00152311]\n",
      "64 3.3289544e-07 [1.0006539] [-0.00148653]\n",
      "65 3.170367e-07 [1.0006381] [-0.00145078]\n",
      "66 3.019659e-07 [1.0006229] [-0.00141588]\n",
      "67 2.8761295e-07 [1.0006078] [-0.00138185]\n",
      "68 2.7389953e-07 [1.0005933] [-0.00134861]\n",
      "69 2.6098792e-07 [1.000579] [-0.00131623]\n",
      "70 2.4854722e-07 [1.000565] [-0.00128458]\n",
      "71 2.3672465e-07 [1.0005515] [-0.00125368]\n",
      "72 2.2548487e-07 [1.0005382] [-0.00122354]\n",
      "73 2.1473623e-07 [1.0005254] [-0.00119411]\n",
      "74 2.045649e-07 [1.0005127] [-0.00116543]\n",
      "75 1.94896e-07 [1.0005003] [-0.00113744]\n",
      "76 1.856131e-07 [1.0004883] [-0.00111008]\n",
      "77 1.7677182e-07 [1.0004766] [-0.00108338]\n",
      "78 1.6837684e-07 [1.0004652] [-0.00105734]\n",
      "79 1.6037096e-07 [1.000454] [-0.00103193]\n",
      "80 1.5277321e-07 [1.000443] [-0.00100713]\n",
      "81 1.4551352e-07 [1.0004324] [-0.0009829]\n",
      "82 1.3853669e-07 [1.000422] [-0.00095926]\n",
      "83 1.3203595e-07 [1.0004119] [-0.00093621]\n",
      "84 1.257094e-07 [1.000402] [-0.0009137]\n",
      "85 1.1977903e-07 [1.0003923] [-0.00089176]\n",
      "86 1.14074204e-07 [1.0003829] [-0.00087033]\n",
      "87 1.0869383e-07 [1.0003736] [-0.00084943]\n",
      "88 1.0348674e-07 [1.0003647] [-0.00082898]\n",
      "89 9.8562715e-08 [1.000356] [-0.00080904]\n",
      "90 9.3912945e-08 [1.0003474] [-0.00078962]\n",
      "91 8.9450886e-08 [1.000339] [-0.00077064]\n",
      "92 8.521005e-08 [1.0003308] [-0.00075213]\n",
      "93 8.112014e-08 [1.0003229] [-0.00073401]\n",
      "94 7.7303135e-08 [1.0003151] [-0.00071639]\n",
      "95 7.359433e-08 [1.0003076] [-0.00069913]\n",
      "96 7.012745e-08 [1.0003002] [-0.00068233]\n",
      "97 6.6794236e-08 [1.0002929] [-0.00066593]\n",
      "98 6.3626835e-08 [1.0002859] [-0.00064991]\n",
      "99 6.059421e-08 [1.0002791] [-0.00063427]\n",
      "\n",
      "X: 5, Y:  [5.000761]\n",
      "X: 2.5, Y:  [2.5000634]\n"
     ]
    }
   ],
   "source": [
    "# 세션을 생성하고 변수들 초기화\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # 최적화 수행 그래프 실행, 실행 시마다 변화하는 손실값 출력\n",
    "    for step in range(100):\n",
    "        # feed_dict 를 통해 x_data 와 y_data 의 상관관계를 알아낸다\n",
    "        _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data, Y: y_data})\n",
    "        \n",
    "        print(step, cost_val, sess.run(W), sess.run(b))\n",
    "        \n",
    "    # X 값을 넣고 결과 확인\n",
    "    print(\"\\nX: 5, Y: \", sess.run(hypothesis, feed_dict={X: 5}))\n",
    "    print(\"X: 2.5, Y: \", sess.run(hypothesis, feed_dict={X: 2.5}))\n",
    "        \n",
    "# 결과를 보면 손실값이 점점 줄어드는것을 확인할 수 있다.\n",
    "# 그리고, X가 5일 때는 Y 값으로 5를 2.5일 때는 2.5를 정확히 예측해내는것을 ㅎ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
